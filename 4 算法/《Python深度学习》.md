# 第一部分 深度学习基础

## 第1章 什么是深度学习 

### 1 人工智能、机器学习与深度学习 

1.1 人工智能 
1.2 机器学习 
1.3 从数据中学习表示 
1.4 深度学习之“深度” 
1.5 用三张图理解深度学习的工作原理 
1.6 深度学习已经取得的进展 
1.7 不要相信短期炒作 
1.8 人工智能的未来 

### 2 深度学习之前：机器学习简史 

2.1 概率建模 
2.2 早期神经网络 
2.3 核方法 
2.4 决策树、随机森林与梯度提升机 
2.5 回到神经网络 
2.6 深度学习有何不同 
2.7 机器学习现状 

### 3 为什么是深度学习，为什么是现在 

3.1 硬件 
3.2 数据 
3.3 算法 
3.4 新的投资热潮 
3.5 深度学习的大众化 
3.6 这种趋势会持续吗 

## 第2章 神经网络的数学基础 

### 1 初识神经网络 

### 2 神经网络的数据表示 

2.1 标量（0D张量） 
2.2 向量（1D张量） 
2.3 矩阵（2D张量） 
2.4 3D张量与更高维张量 
2.5 关键属性 
2.6 在Numpy中操作张量 
2.7 数据批量的概念 
2.8 现实世界中的数据张量 
2.9 向量数据 
2.10 时间序列数据或序列数据 
2.11 图像数据 
2.12 视频数据 

### 3 神经网络的“齿轮”：张量运算 

3.1 逐元素运算 
3.2 广播 
3.3 张量点积 
3.4 张量变形 
3.5 张量运算的几何解释 
3.6 深度学习的几何解释 

### 4 神经网络的“引擎”：基于梯度的优化 

4.1 什么是导数 
4.2 张量运算的导数：梯度 
4.3 随机梯度下降 
4.4 链式求导：反向传播算法 

### 5 回顾第一个例子 

### 本章小结 

## 第3章 神经网络入门 

### 1 神经网络剖析 

1.1 层：深度学习的基础组件 
1.2 模型：层构成的网络 
1.3 损失函数与优化器：配置学习过程的关键 

### 2 Keras简介 

2.1 Keras、TensorFlow、Theano 和CNTK 
2.2 使用Keras 开发：概述 

### 3 建立深度学习工作站 

3.1 Jupyter笔记本：运行深度学习实验的首选方法 
3.2 运行Keras：两种选择 
3.3 在云端运行深度学习任务：优点和缺点 
3.4 深度学习的最佳GPU 

### 4 电影评论分类：二分类问题 

4.1 IMDB 数据集 
4.2 准备数据 
4.3 构建网络 
4.4 验证你的方法 
4.5 使用训练好的网络在新数据上生成预测结果 
4.6 进一步的实验 
4.7 小结 

### 5 新闻分类：多分类问题 

5.1 路透社数据集 
5.2 准备数据 
5.3 构建网络 
5.4 验证你的方法 
5.5 在新数据上生成预测结果 
5.6 处理标签和损失的另一种方法 
5.7 中间层维度足够大的重要性 
5.8 进一步的实验 
5.9 小结 

### 6 预测房价：回归问题 

6.1 波士顿房价数据集 
6.2 准备数据 
6.3 构建网络 
6.4 利用K折验证来验证你的方法 
6.5 小结 

### 本章小结 

## 第4章 机器学习基础 

### 1 机器学习的四个分支 

1.1 监督学习 
1.2 无监督学习 
1.3 自监督学习 
1.4 强化学习 

### 2 评估机器学习模型 

2.1 训练集、验证集和测试集 
2.2 评估模型的注意事项 

### 3 数据预处理、特征工程和特征学习 

3.1 神经网络的数据预处理 
3.2 特征工程 

### 4 过拟合与欠拟合 

4.1 减小网络大小 
4.2 添加权重正则化 
4.3 添加dropout正则化 

### 5 机器学习的通用工作流程 

5.1 定义问题，收集数据集 
5.2 选择衡量成功的指标 
5.3 确定评估方法 
5.4 准备数据 
5.5 开发比基准更好的模型 
5.6 扩大模型规模：开发过拟合的模型 
5.7 模型正则化与调节超参数 

## 本章小结 

# 第二部分 深度学习实践

## 第5章 深度学习用于计算机视觉 

1 卷积神经网络简介 
1.1 卷积运算 
1.2 最大池化运算 
2 在小型数据集上从头开始训练一个卷积神经网络 
2.1 深度学习与小数据问题的相关性 
2.2 下载数据 
2.3 构建网络 
2.4 数据预处理 
2.5 使用数据增强 
3 使用预训练的卷积神经网络 
3.1 特征提取 
3.2 微调模型 
3.3 小结 
4 卷积神经网络的可视化 
4.1 可视化中间激活 
4.2 可视化卷积神经网络的过滤器 
4.3 可视化类激活的热力图 
本章小结 

## 第6章 深度学习用于文本和序列 

### 1 处理文本数据 

1.1 单词和字符的one-hot编码 
1.2 使用词嵌入 
1.3 整合在一起：从原始文本到词嵌入 
1.4 小结 

### 2 理解循环神经网络 

2.1 Keras中的循环层 
2.2 理解LSTM层和GRU层 
2.3 Keras中一个LSTM的具体例子 
2.4 小结 

### 3 循环神经网络的高级用法 

3.1 温度预测问题 
3.2 准备数据 
3.3 一种基于常识的、非机器学习的基准方法 
3.4 一种基本的机器学习方法 
3.5 第一个循环网络基准 
3.6 使用循环dropout来降低过拟合 
3.7 循环层堆叠 
3.8 使用双向RNN 
3.9 更多尝试 
3.10 小结 

### 4 用卷积神经网络处理序列 

4.1 理解序列数据的一维卷积 
4.2 序列数据的一维池化 
4.3 实现一维卷积神经网络 
4.4 结合CNN和RNN来处理长序列 

### 4.5 小结 

### 本章总结 

## 第7章 高级的深度学习最佳实践 

1 不用Sequential模型的解决方案：Keras 函数式API 
1.1 函数式API简介 
1.2 多输入模型 
1.3 多输出模型 
1.4 层组成的有向无环图 
1.5 共享层权重 
1.6 将模型作为层 
1.7 小结 
2 使用Keras回调函数和TensorBoard来检查并监控深度学习模型 
2.1 训练过程中将回调函数作用于模型 
2.2 TensorBoard简介：TensorFlow的可视化框架 
2.3 小结 
3 让模型性能发挥到极致 
3.1 高级架构模式 
3.2 超参数优化 
3.3 模型集成 
3.4 小结 
本章总结 

## 第8章 生成式深度学习 

1 使用LSTM生成文本 
1.1 生成式循环网络简史 
1.2 如何生成序列数据 
1.3 采样策略的重要性 
1.4 实现字符级的LSTM文本生成 
1.5 小结 
2 DeepDream 
2.1 用Keras实现DeepDream 
2.2 小结 
3 神经风格迁移 
3.1 内容损失 
3.2 风格损失 
3.3 用Keras实现神经风格迁移 
3.4 小结 
4 用变分自编码器生成图像 
4.1 从图像的潜在空间中采样 
4.2 图像编辑的概念向量 
4.3 变分自编码器 
4.4 小结 
5 生成式对抗网络简介 
5.1 GAN 的简要实现流程 
5.2 大量技巧 
5.3 生成器 
5.4 判别器 
5.5 对抗网络 
5.6 如何训练DCGAN 
5.7 小结 
本章总结 

## 第9章 总结 

### 1 重点内容回顾 

1.1 人工智能的各种方法 
1.2 深度学习在机器学习领域中的特殊之处 
1.3 如何看待深度学习 
1.4 关键的推动技术 
1.5 机器学习的通用工作流程 
1.6 关键网络架构 
1.7 可能性空间 

### 2 深度学习的局限性 

2.1 将机器学习模型拟人化的风险 
2.2 局部泛化与极端泛化 
2.3 小结 

### 3 深度学习的未来 

3.1 模型即程序 
3.2 超越反向传播和可微层 
3.3 自动化机器学习 
3.4 终身学习与模块化子程序复用 
3.5 长期愿景 

### 4 了解一个快速发展领域的最新进展 

4.1 使用Kaggle练习解决现实世界的问题 
4.2 在arXiv阅读最新进展 
4.3 探索Keras生态系统 

### 5 结束语 

# 附录A 在Ubuntu上安装Keras及其依赖 

# 附录B 在EC2 GPU实例上运行Jupyter笔记本 